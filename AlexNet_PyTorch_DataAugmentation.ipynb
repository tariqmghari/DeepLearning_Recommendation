{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bulgarian-democrat",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coated-tooth",
   "metadata": {},
   "source": [
    "## - Target Bracelet and Lipstick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "orange-spiritual",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_style = pd.read_csv(\"Data/style/style.csv\")\n",
    "\n",
    "df_style = df_style[(df_style[\"product_name\"]== \"lipstick\") | (df_style[\"product_name\"]== \"bracelet\")]\n",
    "df_style.to_csv(\"Data/style_DataAugmentation/style_DA.csv\")\n",
    "imageNameList = df_style[\"file\"].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "careful-board",
   "metadata": {},
   "source": [
    "## - Save them in other File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cultural-rhythm",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "root_dir = 'Data/style/'\n",
    "\n",
    "for i in range(len(imageNameList)):\n",
    "    img = Image.open(root_dir+imageNameList[i])\n",
    "    img.save(\"Data/style_DataAugmentation/\"+imageNameList[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viral-buffalo",
   "metadata": {},
   "source": [
    "## - Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "established-folks",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "from CnnAlgoClass.LoadData import LoadData\n",
    "from torch.utils.data import DataLoader\n",
    "from CnnAlgoClass.AlexNet import AlexNet\n",
    "from CnnAlgoClass.Utils import imshow, modelTrain, modelAccurcy, saveModel, loadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "unsigned-baker",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((170, 170)),\n",
    "    transforms.RandomCrop((150, 140)),\n",
    "    transforms.ColorJitter(brightness=0.5),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomGrayscale(0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.0, 0.0, 0.0], std=[1.0, 1.0, 1.0])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "serious-movement",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LoadData(csv_file='Data/style_DataAugmentation/style_AG.csv', root_dir='Data/DataAugmentation_style', transform = tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "generous-biology",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = j = 0\n",
    "root_dir = 'Data/style_DataAugmentation/'\n",
    "\n",
    "for img, label in dataset:\n",
    "    if int(label) == 1:\n",
    "        name = \"1_3_\"+str(i)+'.png'\n",
    "        i+=1\n",
    "    if int(label) == 7:\n",
    "        name = \"7_3_\"+str(j)+'.png'\n",
    "        j+=1\n",
    "    save_image(img, root_dir+name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upper-championship",
   "metadata": {},
   "source": [
    "# Training / Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "wicked-seating",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = transforms.Compose([\n",
    "  transforms.Resize(256),\n",
    "  transforms.CenterCrop(224),\n",
    "  transforms.ToTensor(),\n",
    "  transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "dataset = LoadData(csv_file='Data\\style_DataAugmentation\\style_1.csv', root_dir='Data\\style_DataAugmentation', transform = tf)\n",
    "\n",
    "data_loader = DataLoader(dataset=dataset, batch_size=20, shuffle=True)\n",
    "\n",
    "classes = ('shoes', 'lipstick', 'handbag', 'nail polish', 'necklace', 'watches', 'ring', 'bracelet', 'boots', 'earrings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "streaming-smooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "alex = AlexNet().to(device)\n",
    "\n",
    "loadModel(alex, './models/AlexNet_Adam_VF.pth')\n",
    "\n",
    "optimizer = torch.optim.Adam(alex.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "political-terminal",
   "metadata": {},
   "source": [
    "## - Training 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "useful-amount",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training started ---\n",
      "epoch: 1 loss: 0.8553\n",
      "--- Finished Training ---\n"
     ]
    }
   ],
   "source": [
    "modelTrain(alex, data_loader, optimizer, criterion, epoch=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blocked-granny",
   "metadata": {},
   "source": [
    "## - Testing 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "stunning-porter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Accuracy for each class ----\n",
      "- shoes : 78.77 %\n",
      "- lipstick : 89.04 %\n",
      "- handbag : 81.15 %\n",
      "- nail polish : 28.57 %\n",
      "- necklace : 56.00 %\n",
      "- watches : 73.72 %\n",
      "-  ring : 41.84 %\n",
      "- bracelet : 81.82 %\n",
      "- boots : 62.66 %\n",
      "- earrings : 67.07 %\n",
      "--------------------------------------------------\n",
      "Accuracy of the network on the test images: 69.69 %\n"
     ]
    }
   ],
   "source": [
    "dataset1 = LoadData(csv_file='Data\\style\\style.csv', root_dir='Data\\style', transform = tf)\n",
    "data_loader1 = DataLoader(dataset=dataset1, batch_size=20, shuffle=True)\n",
    "\n",
    "modelAccurcy(alex, data_loader1, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "violent-multimedia",
   "metadata": {},
   "source": [
    "## - Training 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "focal-landscape",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training started ---\n",
      "epoch: 1 loss: 0.7550\n",
      "--- Finished Training ---\n"
     ]
    }
   ],
   "source": [
    "modelTrain(alex, data_loader, optimizer, criterion, epoch=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "african-niagara",
   "metadata": {},
   "source": [
    "## - Testing 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "dressed-jacob",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Accuracy for each class ----\n",
      "- shoes : 83.15 %\n",
      "- lipstick : 93.42 %\n",
      "- handbag : 66.59 %\n",
      "- nail polish : 50.65 %\n",
      "- necklace : 60.67 %\n",
      "- watches : 71.53 %\n",
      "-  ring : 71.94 %\n",
      "- bracelet : 67.77 %\n",
      "- boots : 77.22 %\n",
      "- earrings : 75.00 %\n",
      "--------------------------------------------------\n",
      "Accuracy of the network on the test images: 73.58 %\n"
     ]
    }
   ],
   "source": [
    "modelAccurcy(alex, data_loader1, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "obvious-swimming",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Model saved successfully'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saveModel(alex, './models/AlexNet_Adam_DA.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "academic-anxiety",
   "metadata": {},
   "source": [
    "## - Training 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "molecular-purpose",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training started ---\n",
      "epoch: 1 loss: 0.7492\n",
      "--- Finished Training ---\n"
     ]
    }
   ],
   "source": [
    "modelTrain(alex, data_loader, optimizer, criterion, epoch=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "linear-story",
   "metadata": {},
   "source": [
    "## - Testing 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "smaller-dietary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Accuracy for each class ----\n",
      "- shoes : 89.93 %\n",
      "- lipstick : 93.42 %\n",
      "- handbag : 82.58 %\n",
      "- nail polish : 22.08 %\n",
      "- necklace : 65.33 %\n",
      "- watches : 60.58 %\n",
      "-  ring : 41.33 %\n",
      "- bracelet : 74.38 %\n",
      "- boots : 63.29 %\n",
      "- earrings : 82.32 %\n",
      "--------------------------------------------------\n",
      "Accuracy of the network on the test images: 72.85 %\n"
     ]
    }
   ],
   "source": [
    "modelAccurcy(alex, data_loader1, classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
