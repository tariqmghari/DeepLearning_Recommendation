{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "legitimate-geography",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from CnnAlgoClass.AlexNet import AlexNet\n",
    "from CnnAlgoClass.AlexTest import AlexV1, AlexVE\n",
    "from CnnAlgoClass.LoadData import LoadData\n",
    "from CnnAlgoClass.Utils import imshow, modelTrain, modelAccurcy, saveModel, loadModel\n",
    "from CnnAlgoClass.Similarity import extract_imgsFeatures, product_similatity, imgs_names, similar_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "rental-drink",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = transforms.Compose([\n",
    "  transforms.Resize(256),\n",
    "  transforms.CenterCrop(224),\n",
    "  transforms.ToTensor(),\n",
    "  transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "dataset = LoadData(csv_file='Data\\style\\style.csv', root_dir='Data\\style', transform = tf)\n",
    "\n",
    "data_loader = DataLoader(dataset=dataset, batch_size=20, shuffle=True)\n",
    "\n",
    "classes = ('shoes', 'lipstick', 'handbag', 'nail polish', 'necklace', 'watches', 'ring', 'bracelet', 'boots', 'earrings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "actual-hearing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Model loaded successfully'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alex_adam = AlexNet()\n",
    "alex_adamVF = AlexNet()\n",
    "alex_sgd = AlexNet()\n",
    "\n",
    "loadModel(alex_adam, './models/AlexNet_Adam.pth')\n",
    "loadModel(alex_adamVF, './models/AlexNet_Adam_VF.pth')      \n",
    "loadModel(alex_sgd, './models/AlexNet_SGD.pth')             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "controlled-seeker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Accuracy for each class ----\n",
      "- shoes : 92.78 %\n",
      "- lipstick : 48.68 %\n",
      "- handbag : 88.54 %\n",
      "- nail polish : 74.68 %\n",
      "- necklace : 83.33 %\n",
      "- watches : 72.99 %\n",
      "-  ring : 75.51 %\n",
      "- bracelet : 47.11 %\n",
      "- boots : 78.48 %\n",
      "- earrings : 87.20 %\n",
      "--------------------------------------------------\n",
      "Accuracy of the network on the test images: 78.66 %\n"
     ]
    }
   ],
   "source": [
    "modelAccurcy(alex_adamVF, data_loader, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "optional-burst",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Accuracy for each class ----\n",
      "- shoes : 87.75 %\n",
      "- lipstick : 69.74 %\n",
      "- handbag : 81.86 %\n",
      "- nail polish : 68.83 %\n",
      "- necklace : 60.67 %\n",
      "- watches : 61.31 %\n",
      "-  ring : 85.20 %\n",
      "- bracelet : 49.59 %\n",
      "- boots : 67.72 %\n",
      "- earrings : 81.71 %\n",
      "--------------------------------------------------\n",
      "Accuracy of the network on the test images: 75.64 %\n"
     ]
    }
   ],
   "source": [
    "modelAccurcy(alex_adam, data_loader, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "going-capitol",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Accuracy for each class ----\n",
      "- shoes : 79.65 %\n",
      "- lipstick : 66.67 %\n",
      "- handbag : 65.63 %\n",
      "- nail polish : 0.00 %\n",
      "- necklace : 59.33 %\n",
      "- watches : 49.64 %\n",
      "-  ring : 33.67 %\n",
      "- bracelet : 0.83 %\n",
      "- boots : 49.37 %\n",
      "- earrings : 32.32 %\n",
      "--------------------------------------------------\n",
      "Accuracy of the network on the test images: 52.47 %\n"
     ]
    }
   ],
   "source": [
    "modelAccurcy(alex_sgd, data_loader, classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
